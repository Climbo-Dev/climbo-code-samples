{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "6d06cafd-abaf-4784-b055-e4abfd02606d",
   "metadata": {},
   "source": [
    "# FastAI NLP Study Notes"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bb0f561d-6022-4b5b-886c-fd74afc6ae92",
   "metadata": {},
   "source": [
    "In this notebook, we try to replicate models implemented in [A Language Model from Scratch](https://github.com/fastai/fastbook/blob/master/12_nlp_dive.ipynb). \n",
    "\n",
    "We will use the *Human Numbers* dataset, and it simply contains the first 10,000 numbers written out in English."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "b1910c89-e246-4bc0-b566-6538722292c8",
   "metadata": {},
   "outputs": [],
   "source": [
    "from fastcore.utils import L\n",
    "from fastai.text.all import *\n",
    "path = untar_data(URLs.HUMAN_NUMBERS)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "3b115d84-a6a7-4299-9d0e-71c202cd2a9f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((#5) ['one \\n','two \\n','three \\n','four \\n','five \\n'],\n",
       " (#5) ['nine thousand nine hundred ninety five \\n','nine thousand nine hundred ninety six \\n','nine thousand nine hundred ninety seven \\n','nine thousand nine hundred ninety eight \\n','nine thousand nine hundred ninety nine \\n'])"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lines = L()\n",
    "with open(path / \"train.txt\", 'r') as f: lines += L(*f.readlines())\n",
    "with open(path / \"valid.txt\", 'r') as f: lines += L(*f.readlines())\n",
    "lines[:5], lines[-5:]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ded22bd9-3aa7-433f-bb23-3ac9180c5c51",
   "metadata": {},
   "source": [
    "The data set is quite simple, we can build our own the **tokenizer** and **word2vec** tool."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "3982133b-e216-491a-bbbc-6e1f48f8286f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(['one', '.', 'two', '.', 'three'],\n",
       " ['thousand', 'nine', 'hundred', 'ninety', 'nine'])"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "text = \" . \".join([x.strip() for x in lines])\n",
    "tokens = text.split(' ')\n",
    "tokens[:5], tokens[-5:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "4b8666ee-c09e-410b-b421-ef9f3171c332",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(#63095) [0,1,2,1,3,1,4,1,5,1...]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vocab = L(*tokens).unique()\n",
    "word2idx = {t:i for i, t in enumerate(vocab)}\n",
    "indices = L(word2idx[t] for t in tokens)\n",
    "indices"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "272b62a8-3cc7-4ee4-9091-337cdd086093",
   "metadata": {},
   "source": [
    "## Our First Language Model from Scratch\n",
    "\n",
    "We will build a model that predicts the next word by looking at the previous 3 words."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "b3679f27-3afb-4a0e-81a3-61d8e89bc9b5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "([(['one', '.', 'two'], '.'),\n",
       "  (['three', '.', 'four'], '.'),\n",
       "  (['five', '.', 'six'], '.'),\n",
       "  (['seven', '.', 'eight'], '.'),\n",
       "  (['nine', '.', 'ten'], '.')],\n",
       " [(['ninety', 'six', '.'], 'nine'),\n",
       "  (['thousand', 'nine', 'hundred'], 'ninety'),\n",
       "  (['seven', '.', 'nine'], 'thousand'),\n",
       "  (['nine', 'hundred', 'ninety'], 'eight'),\n",
       "  (['.', 'nine', 'thousand'], 'nine')])"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import torch\n",
    "from torch import tensor\n",
    "\n",
    "raw_seqs = [(tokens[i:(i+3)], tokens[i+3]) for i in range(0, len(tokens)-3, 4)]\n",
    "raw_seqs[:5], raw_seqs[-5:]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "96ce837f-bfc3-49ad-9aaa-e11f9123ab8b",
   "metadata": {},
   "source": [
    "Since we cannot feed our model raw text, we need to use indices instead."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "2edb0802-f85a-4fdb-ac47-228f29f3240e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(#21031) [(tensor([0, 1, 2]), 1),(tensor([1, 3, 1]), 4),(tensor([4, 1, 5]), 1),(tensor([1, 6, 1]), 7),(tensor([7, 1, 8]), 1),(tensor([1, 9, 1]), 10),(tensor([10,  1, 11]), 1),(tensor([ 1, 12,  1]), 13),(tensor([13,  1, 14]), 1),(tensor([ 1, 15,  1]), 16)...]"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "seqs = L((tensor(indices[i:(i+3)]), indices[i+3]) for i in range(0, len(indices)-4, 3))\n",
    "seqs"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "683b57f5-eeba-409f-b475-da9da3cc1728",
   "metadata": {},
   "source": [
    "### A Simple Language Model - Explicit Layers"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4aad33cc-d421-454d-aace-69f2b4c84c59",
   "metadata": {},
   "source": [
    "Model architecture:\n",
    "\n",
    "<img src=\"https://raw.githubusercontent.com/Climbo-Dev/climbo-code-samples/main/images/fastbook_12_nlp_att_00022.png\" width=\"500\">\n",
    "\n",
    "- rectangles are embeddings\n",
    "- arrows are linear transformations\n",
    "- ellipses are hidden layer transformations (linear combination + ReLU)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "d2ef5112-1d35-4cf7-9d3d-51c1894da03a",
   "metadata": {},
   "outputs": [],
   "source": [
    "class LMModel(Module):\n",
    "    def __init__(self, vocab_size, n_hidden):\n",
    "        self.i_h = nn.Embedding(vocab_size, n_hidden)\n",
    "        self.h_h = nn.Linear(n_hidden, n_hidden)\n",
    "        # the output is a very lone vector so we know which word we are predicting.\n",
    "        self.h_o = nn.Linear(n_hidden, vocab_size)\n",
    "\n",
    "    def forward(self, x):\n",
    "        i_h, h_h, h_o = self.i_h, self.h_h, self.h_o\n",
    "\n",
    "        x1 = i_h(x[:,0])\n",
    "        x2 = i_h(x[:,1])\n",
    "        x3 = i_h(x[:,2])\n",
    "        \n",
    "        h = F.relu(h_h(x1))\n",
    "        h = F.relu(h_h(x2) + h)\n",
    "        h = F.relu(h_h(x3) + h)\n",
    "\n",
    "        return h_o(h)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b7a24828-9567-449b-b478-6a63bcba5100",
   "metadata": {},
   "source": [
    "Load data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "6a717734-d296-41db-8904-d388c9254db4",
   "metadata": {},
   "outputs": [],
   "source": [
    "bs = 64\n",
    "cut = int(len(seqs) * 0.8)\n",
    "dls = DataLoaders.from_dsets(seqs[:cut], seqs[cut:], bs=64, shuffle=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "850e90e7-016b-475e-84d7-20f1c4b8c721",
   "metadata": {},
   "source": [
    "Let's see how the model work on a batch:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "276fde88-2200-4ae4-ade0-5b5999a33a69",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([64, 3]) torch.Size([64]) torch.Size([64, 30])\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "tensor([[ 0.0185, -0.4614,  0.5482,  ...,  0.8765, -0.1430,  1.4199],\n",
       "        [ 0.0480, -0.5438, -0.2975,  ...,  1.0006,  0.8631,  1.0290],\n",
       "        [-0.0047, -0.2217, -0.6078,  ...,  0.2592,  0.8370,  0.6079],\n",
       "        ...,\n",
       "        [-0.5158,  0.4641,  0.1081,  ...,  0.4880, -0.1568,  0.6477],\n",
       "        [-0.2396,  0.2414,  0.4456,  ...,  0.6800, -0.4271,  0.6313],\n",
       "        [-0.4916,  0.1453,  0.2579,  ...,  0.6784, -0.1513,  0.9050]],\n",
       "       grad_fn=<AddmmBackward0>)"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = LMModel(len(vocab), 10)\n",
    "x, y = next(iter(dls.train))\n",
    "output = model(x)\n",
    "print(x.shape, y.shape, output.shape)\n",
    "output"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "da19f1fc-116e-4138-a0e9-787a7a702e2b",
   "metadata": {},
   "source": [
    "Now we can train the model:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "de782334-9a1a-42e6-8f76-c332dec9a133",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "<style>\n",
       "    /* Turns off some styling */\n",
       "    progress {\n",
       "        /* gets rid of default border in Firefox and Opera. */\n",
       "        border: none;\n",
       "        /* Needs to be in here for Safari polyfill so background images work as expected. */\n",
       "        background-size: auto;\n",
       "    }\n",
       "    progress:not([value]), progress:not([value])::-webkit-progress-bar {\n",
       "        background: repeating-linear-gradient(45deg, #7e7e7e, #7e7e7e 10px, #5c5c5c 10px, #5c5c5c 20px);\n",
       "    }\n",
       "    .progress-bar-interrupted, .progress-bar-interrupted::-webkit-progress-bar {\n",
       "        background: #F44336;\n",
       "    }\n",
       "</style>\n"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>epoch</th>\n",
       "      <th>train_loss</th>\n",
       "      <th>valid_loss</th>\n",
       "      <th>accuracy</th>\n",
       "      <th>time</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>2.021665</td>\n",
       "      <td>2.377312</td>\n",
       "      <td>0.323033</td>\n",
       "      <td>00:02</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>1.490597</td>\n",
       "      <td>1.938966</td>\n",
       "      <td>0.444260</td>\n",
       "      <td>00:02</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>1.468995</td>\n",
       "      <td>1.673518</td>\n",
       "      <td>0.486095</td>\n",
       "      <td>00:02</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>1.426818</td>\n",
       "      <td>1.718666</td>\n",
       "      <td>0.376753</td>\n",
       "      <td>00:02</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "learner = Learner(dls, LMModel(len(vocab), 64), loss_func=F.cross_entropy, metrics=accuracy)\n",
    "learner.fit_one_cycle(4, 0.001)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "21056ea8-28df-44a6-a9dd-f94246370699",
   "metadata": {},
   "source": [
    "Compare the result with the simple benchmark of using only the most frequent token:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "3a82d6ea-9cd5-4e71-bc41-4a85d0d99783",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "most frequent word: thousand, frequency of the most frequent word: 0.15165200855716662\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "ys = torch.concat([y for _, y in dls.valid])\n",
    "ys = pd.Series(ys)\n",
    "most_frequent = ys.value_counts().head(1)\n",
    "mw = vocab[most_frequent.index[0]]\n",
    "mf = most_frequent.values[0] / ys.shape[0]\n",
    "print(f\"most frequent word: {mw}, frequency of the most frequent word: {mf}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "013078c2-6149-44c5-82c4-7d56d574c35e",
   "metadata": {},
   "source": [
    "### A Simple Recurrent Language Model\n",
    "\n",
    "We can simplify the previous model by using a simple for loop:\n",
    "\n",
    "<img src=\"https://raw.githubusercontent.com/Climbo-Dev/climbo-code-samples/main/images/fastbook_12_nlp_att_00070.png\" width=\"500\">"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "f686879b-5430-4e65-a026-cd1df954cb8f",
   "metadata": {},
   "outputs": [],
   "source": [
    "class LMModel2(Module):\n",
    "    def __init__(self, vocab_size, n_hidden):\n",
    "        self.i_h = nn.Embedding(vocab_size, n_hidden)\n",
    "        self.h_h = nn.Linear(n_hidden, n_hidden)\n",
    "        self.h_o = nn.Linear(n_hidden, vocab_size)\n",
    "\n",
    "    def forward(self, x):\n",
    "        h = 0\n",
    "        for i in range(3):\n",
    "            h = h + self.i_h(x[:,i])\n",
    "            h = F.relu(self.h_h(h))\n",
    "        return self.h_o(h)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "90107362-ab87-4ed5-9896-ee149e327bcd",
   "metadata": {},
   "source": [
    "The model should have the same architecture with `LMModel`:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "29b46654-0ea4-4ac7-a7a7-105e026ee6d4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "<style>\n",
       "    /* Turns off some styling */\n",
       "    progress {\n",
       "        /* gets rid of default border in Firefox and Opera. */\n",
       "        border: none;\n",
       "        /* Needs to be in here for Safari polyfill so background images work as expected. */\n",
       "        background-size: auto;\n",
       "    }\n",
       "    progress:not([value]), progress:not([value])::-webkit-progress-bar {\n",
       "        background: repeating-linear-gradient(45deg, #7e7e7e, #7e7e7e 10px, #5c5c5c 10px, #5c5c5c 20px);\n",
       "    }\n",
       "    .progress-bar-interrupted, .progress-bar-interrupted::-webkit-progress-bar {\n",
       "        background: #F44336;\n",
       "    }\n",
       "</style>\n"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>epoch</th>\n",
       "      <th>train_loss</th>\n",
       "      <th>valid_loss</th>\n",
       "      <th>accuracy</th>\n",
       "      <th>time</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>1.841735</td>\n",
       "      <td>2.018465</td>\n",
       "      <td>0.472070</td>\n",
       "      <td>00:02</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>1.367022</td>\n",
       "      <td>1.797690</td>\n",
       "      <td>0.480628</td>\n",
       "      <td>00:02</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>1.429261</td>\n",
       "      <td>1.671371</td>\n",
       "      <td>0.491799</td>\n",
       "      <td>00:02</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>1.385907</td>\n",
       "      <td>1.664714</td>\n",
       "      <td>0.489422</td>\n",
       "      <td>00:02</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "bs = 64\n",
    "cut = int(len(seqs) * 0.8)\n",
    "dls = DataLoaders.from_dsets(seqs[:cut], seqs[cut:], bs=64, shuffle=False)\n",
    "\n",
    "# Train the Model\n",
    "learner = Learner(dls, LMModel2(len(vocab), 64), loss_func=F.cross_entropy, metrics=accuracy)\n",
    "learner.fit_one_cycle(4, 0.001)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ac2eb814-476f-4956-8e1c-36dc95fa2373",
   "metadata": {},
   "source": [
    "### A Recurrent Language Model with Memory\n",
    "\n",
    "The previous model resets hidden state variables to 0 for every forward path. However, if we feed the model with words from a consecutive sequence, hidden state variables fitted from previous words should be useful traing the current model. \n",
    "\n",
    "<img src=\"https://raw.githubusercontent.com/Climbo-Dev/climbo-code-samples/main/images/fastbook_12_nlp_att_00024.png\" width=\"500\">\n",
    "\n",
    "To allow our language model to memorize prior states informations, we shall initialize the hidden variable once and carry its value between forward paths:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "1545b013-d32f-436e-90bf-99b34476a7ae",
   "metadata": {},
   "outputs": [],
   "source": [
    "class LMModel3(Module):\n",
    "    def __init__(self, vocab_size, n_hidden, detach:bool):\n",
    "        self.i_h = nn.Embedding(vocab_size, n_hidden)\n",
    "        self.h_h = nn.Linear(n_hidden, n_hidden)\n",
    "        self.h_o = nn.Linear(n_hidden, vocab_size)\n",
    "        self.h = 0\n",
    "        self.detach = detach\n",
    "\n",
    "    def forward(self, x):\n",
    "        for i in range(3):\n",
    "            self.h = self.h + self.i_h(x[:,i])\n",
    "            self.h = F.relu(self.h_h(self.h))\n",
    "        output = self.h_o(self.h)\n",
    "        if self.detach:\n",
    "            self.h = self.h.detach()  # !!! We should always detach h, see explanations below\n",
    "        return output\n",
    "\n",
    "    def reset(self):\n",
    "        self.h = 0"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0223a492-286d-448c-8165-da6e4a35cb23",
   "metadata": {},
   "source": [
    "Since we need to feed this model consecutive tokens, we need to create batches by ourselves.\n",
    "\n",
    "The `group_chunks` function below re-order the original sequence so batches, when procressed sequentially, reproduces the original word sequence. (This method is hacky though)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "95350cf9-2cf7-4785-bf59-1cfc25a6e5ff",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(#50) [(['one', '.', 'two'], '.'),(['eleven', '.', 'twelve'], '.'),(['twenty', 'one', '.'], 'twenty'),(['.', 'twenty', 'eight'], '.'),(['.', 'thirty', 'five'], '.'),(['.', 'forty', 'two'], '.'),(['eight', '.', 'forty'], 'nine'),(['five', '.', 'fifty'], 'six'),(['two', '.', 'sixty'], 'three'),(['sixty', 'nine', '.'], 'seventy')...]"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def group_chunks(ds, bs):\n",
    "    m = len(ds) // bs\n",
    "    new_ds = L()\n",
    "    for i in range(m): new_ds += L(ds[i + m*j] for j in range(bs))\n",
    "    return new_ds\n",
    "\n",
    "chunks = group_chunks(raw_seqs[:50], 10) # visualize using original tokens\n",
    "chunks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "3816754d-c235-4f9a-8a10-c305725f3a96",
   "metadata": {},
   "outputs": [],
   "source": [
    "cut = int(len(seqs) * 0.8)\n",
    "dls = DataLoaders.from_dsets(\n",
    "    group_chunks(seqs[:cut], bs), \n",
    "    group_chunks(seqs[cut:], bs), \n",
    "    bs=bs, drop_last=True, shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "6f738ff4-7a1f-4083-a7c3-ecccf675918c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "<style>\n",
       "    /* Turns off some styling */\n",
       "    progress {\n",
       "        /* gets rid of default border in Firefox and Opera. */\n",
       "        border: none;\n",
       "        /* Needs to be in here for Safari polyfill so background images work as expected. */\n",
       "        background-size: auto;\n",
       "    }\n",
       "    progress:not([value]), progress:not([value])::-webkit-progress-bar {\n",
       "        background: repeating-linear-gradient(45deg, #7e7e7e, #7e7e7e 10px, #5c5c5c 10px, #5c5c5c 20px);\n",
       "    }\n",
       "    .progress-bar-interrupted, .progress-bar-interrupted::-webkit-progress-bar {\n",
       "        background: #F44336;\n",
       "    }\n",
       "</style>\n"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>epoch</th>\n",
       "      <th>train_loss</th>\n",
       "      <th>valid_loss</th>\n",
       "      <th>accuracy</th>\n",
       "      <th>time</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>1.732836</td>\n",
       "      <td>1.862581</td>\n",
       "      <td>0.474279</td>\n",
       "      <td>00:02</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>1.292882</td>\n",
       "      <td>1.808473</td>\n",
       "      <td>0.448317</td>\n",
       "      <td>00:02</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>1.080552</td>\n",
       "      <td>1.804297</td>\n",
       "      <td>0.490625</td>\n",
       "      <td>00:02</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>1.004886</td>\n",
       "      <td>1.654634</td>\n",
       "      <td>0.514183</td>\n",
       "      <td>00:02</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>0.958965</td>\n",
       "      <td>1.742390</td>\n",
       "      <td>0.550481</td>\n",
       "      <td>00:03</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5</td>\n",
       "      <td>0.901038</td>\n",
       "      <td>1.753155</td>\n",
       "      <td>0.579567</td>\n",
       "      <td>00:02</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>6</td>\n",
       "      <td>0.862871</td>\n",
       "      <td>1.705840</td>\n",
       "      <td>0.579327</td>\n",
       "      <td>00:02</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>7</td>\n",
       "      <td>0.816607</td>\n",
       "      <td>1.590275</td>\n",
       "      <td>0.589183</td>\n",
       "      <td>00:02</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>8</td>\n",
       "      <td>0.782191</td>\n",
       "      <td>1.628739</td>\n",
       "      <td>0.601683</td>\n",
       "      <td>00:02</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>9</td>\n",
       "      <td>0.772643</td>\n",
       "      <td>1.620571</td>\n",
       "      <td>0.600000</td>\n",
       "      <td>00:02</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "learn = Learner(dls, LMModel3(len(vocab), 64, True), loss_func=F.cross_entropy,\n",
    "                metrics=accuracy, cbs=ModelResetter)\n",
    "learn.fit_one_cycle(10, 3e-3)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2e3cd086-d9e2-4611-a2de-3fcefff525b2",
   "metadata": {},
   "source": [
    "If we do not detach, we got a RunTimeError:\n",
    "\n",
    "```\n",
    "RuntimeError: Trying to backward through the graph a second time (or directly access saved tensors after they have already been freed). Saved intermediate values of the graph are freed when you call .backward() or autograd.grad(). Specify retain_graph=True if you need to backward through the graph a second time or if you need to access saved tensors after calling backward.\n",
    "```\n",
    "\n",
    "**TODO**: investigate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "07a2e880-9bbf-4207-b875-cd375e98ef16",
   "metadata": {},
   "outputs": [],
   "source": [
    "learn = Learner(dls, LMModel3(len(vocab), 64, False), loss_func=F.cross_entropy,\n",
    "                metrics=accuracy, cbs=ModelResetter)\n",
    "# learn.fit_one_cycle(4, 3e-3)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2a8bdff8-15ca-418d-8d15-1ab02b962b71",
   "metadata": {},
   "source": [
    "### Creating More Signals\n",
    "\n",
    "In previous examples, our input data are disjoint. It would be better if we can predict every word by looking at the previous n words. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "id": "889ce6eb-7ee6-4bbe-b328-b7c7c85aaf1a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[['one', '.', 'two', '.', 'three', '.', 'four', '.', 'five', '.', 'six', '.', 'seven', '.', 'eight', '.'], ['.', 'two', '.', 'three', '.', 'four', '.', 'five', '.', 'six', '.', 'seven', '.', 'eight', '.', 'nine']]\n",
      "[['nine', '.', 'ten', '.', 'eleven', '.', 'twelve', '.', 'thirteen', '.', 'fourteen', '.', 'fifteen', '.', 'sixteen', '.'], ['.', 'ten', '.', 'eleven', '.', 'twelve', '.', 'thirteen', '.', 'fourteen', '.', 'fifteen', '.', 'sixteen', '.', 'seventeen']]\n"
     ]
    }
   ],
   "source": [
    "sl = 16  # sequence length\n",
    "seqs = L((tensor(indices[i:i+sl]), tensor(indices[i+1:i+sl+1])) for i in range(0, len(indices)-sl-1, sl))\n",
    "print([L([vocab[o] for o in s]) for s in seqs[0]])\n",
    "print([L([vocab[o] for o in s]) for s in seqs[1]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "id": "b5009201-7488-4a46-8da2-73d0cf9f8986",
   "metadata": {},
   "outputs": [],
   "source": [
    "cut = int(len(seqs) * 0.8)\n",
    "dls = DataLoaders.from_dsets(group_chunks(seqs[:cut], bs), group_chunks(seqs[cut:], bs), bs=bs, drop_last=True, shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "id": "9f304551-e76b-4487-83c6-f88550537b3c",
   "metadata": {},
   "outputs": [],
   "source": [
    "class LMModel4(Module):\n",
    "    def __init__(self, vocab_sz, n_hidden):\n",
    "        self.i_h = nn.Embedding(vocab_sz, n_hidden)\n",
    "        self.h_h = nn.Linear(n_hidden, n_hidden)\n",
    "        self.h_o = nn.Linear(n_hidden, vocab_sz)\n",
    "        self.h = 0\n",
    "\n",
    "    def forward(self, x):\n",
    "        outs = []\n",
    "        for i in range(sl):\n",
    "            self.h = self.h + self.i_h(x[:,i])\n",
    "            self.h = F.relu(self.h_h(self.h))\n",
    "            outs.append(self.h_o(self.h))\n",
    "        self.h = self.h.detach()\n",
    "        return torch.stack(outs, dim=1)\n",
    "\n",
    "    def reset(self):\n",
    "        self.h = 0"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9f880dad-3f55-4b4e-a137-ae5939aecfbc",
   "metadata": {},
   "source": [
    "We need to define a new loss function. Target is of size `bs x sl`, input is of size `bs x sl x vocab_sz`:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "id": "6a50ecf8-69ec-40e6-8b57-d2251e5c107f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def loss_func(input, target):\n",
    "    return F.cross_entropy(input.view(-1, len(vocab)), target.view(-1))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bc49e61e-8cef-4fda-ad0f-aae72dace57b",
   "metadata": {},
   "source": [
    "Let's test how the model perform on a small batch:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "id": "d1cde97f-4c28-4f3b-b002-4c7d022db85c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "input: torch.Size([2, 16, 30]) torch.Size([32, 30])\n",
      "target: torch.Size([2, 16]) torch.Size([32])\n",
      "loss: tensor(3.5521, grad_fn=<NllLossBackward0>)\n"
     ]
    }
   ],
   "source": [
    "x = torch.vstack([seqs[0][0], seqs[1][0]])\n",
    "target = torch.vstack([seqs[0][1], seqs[1][1]])\n",
    "model = LMModel4(len(vocab), 64)\n",
    "input = model(x)\n",
    "print(\"input:\", input.size(), input.view(-1, len(vocab)).size())\n",
    "print(\"target:\", target.size(), target.view(-1).size())\n",
    "print(\"loss:\", loss_func(input, target))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "932fefad-891f-4827-9faf-a5ac578dedb7",
   "metadata": {},
   "source": [
    "We can now train the model:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "id": "6d5ad41c-ff6f-40f8-ad66-f46282842163",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "<style>\n",
       "    /* Turns off some styling */\n",
       "    progress {\n",
       "        /* gets rid of default border in Firefox and Opera. */\n",
       "        border: none;\n",
       "        /* Needs to be in here for Safari polyfill so background images work as expected. */\n",
       "        background-size: auto;\n",
       "    }\n",
       "    progress:not([value]), progress:not([value])::-webkit-progress-bar {\n",
       "        background: repeating-linear-gradient(45deg, #7e7e7e, #7e7e7e 10px, #5c5c5c 10px, #5c5c5c 20px);\n",
       "    }\n",
       "    .progress-bar-interrupted, .progress-bar-interrupted::-webkit-progress-bar {\n",
       "        background: #F44336;\n",
       "    }\n",
       "</style>\n"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>epoch</th>\n",
       "      <th>train_loss</th>\n",
       "      <th>valid_loss</th>\n",
       "      <th>accuracy</th>\n",
       "      <th>time</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>3.202699</td>\n",
       "      <td>3.065444</td>\n",
       "      <td>0.251709</td>\n",
       "      <td>00:01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>2.281799</td>\n",
       "      <td>1.886787</td>\n",
       "      <td>0.400065</td>\n",
       "      <td>00:01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>1.719919</td>\n",
       "      <td>1.768146</td>\n",
       "      <td>0.487712</td>\n",
       "      <td>00:01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>1.414626</td>\n",
       "      <td>1.720758</td>\n",
       "      <td>0.530192</td>\n",
       "      <td>00:01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>1.242322</td>\n",
       "      <td>1.813718</td>\n",
       "      <td>0.547526</td>\n",
       "      <td>00:01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5</td>\n",
       "      <td>1.101264</td>\n",
       "      <td>1.762658</td>\n",
       "      <td>0.569987</td>\n",
       "      <td>00:01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>6</td>\n",
       "      <td>0.995921</td>\n",
       "      <td>1.701138</td>\n",
       "      <td>0.588053</td>\n",
       "      <td>00:01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>7</td>\n",
       "      <td>0.899640</td>\n",
       "      <td>1.758914</td>\n",
       "      <td>0.593018</td>\n",
       "      <td>00:01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>8</td>\n",
       "      <td>0.823680</td>\n",
       "      <td>1.759491</td>\n",
       "      <td>0.591064</td>\n",
       "      <td>00:01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>9</td>\n",
       "      <td>0.769644</td>\n",
       "      <td>1.754826</td>\n",
       "      <td>0.582682</td>\n",
       "      <td>00:01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>10</td>\n",
       "      <td>0.730461</td>\n",
       "      <td>1.780050</td>\n",
       "      <td>0.567546</td>\n",
       "      <td>00:01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>11</td>\n",
       "      <td>0.691751</td>\n",
       "      <td>1.710672</td>\n",
       "      <td>0.592041</td>\n",
       "      <td>00:01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>12</td>\n",
       "      <td>0.664783</td>\n",
       "      <td>1.718246</td>\n",
       "      <td>0.583089</td>\n",
       "      <td>00:01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>13</td>\n",
       "      <td>0.648276</td>\n",
       "      <td>1.693145</td>\n",
       "      <td>0.585449</td>\n",
       "      <td>00:01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>14</td>\n",
       "      <td>0.632231</td>\n",
       "      <td>1.726514</td>\n",
       "      <td>0.585368</td>\n",
       "      <td>00:01</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "learn = Learner(dls, LMModel4(len(vocab), 64), loss_func=loss_func, metrics=accuracy, cbs=ModelResetter)\n",
    "learn.fit_one_cycle(15, 3e-3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "id": "69d80a73-89cd-4de4-86e9-fd552e2545c9",
   "metadata": {},
   "outputs": [],
   "source": [
    "x, y = next(iter(dls.train))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9970f4d6-0d9b-4e0f-9205-4a502d9595dd",
   "metadata": {},
   "source": [
    "### LSTM\n",
    "\n",
    "<img src=\"https://raw.githubusercontent.com/Climbo-Dev/climbo-code-samples/main/images/fastbook_12_nlp_LSTM.png\" width=\"800\">"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "id": "1f9cbdd7-7cc4-4ffb-8501-5e914b581865",
   "metadata": {},
   "outputs": [],
   "source": [
    "class LSTMCellSimple(Module):\n",
    "    def __init__(self, ni, nh):\n",
    "        self.forget_gate = nn.Linear(ni + nh, nh)\n",
    "        self.input_gate  = nn.Linear(ni + nh, nh)\n",
    "        self.cell_gate   = nn.Linear(ni + nh, nh)\n",
    "        self.output_gate = nn.Linear(ni + nh, nh)\n",
    "\n",
    "    def forward(self, input, state):\n",
    "        h, c = state\n",
    "        h = torch.cat([h, input], dim=1)\n",
    "        forget = torch.sigmoid(self.forget_gate(h))\n",
    "        c = c * forget\n",
    "        inp = torch.sigmoid(self.input_gate(h))\n",
    "        cell = torch.tanh(self.cell_gate(h))\n",
    "        c = c + inp * cell\n",
    "        out = torch.sigmoid(self.output_gate(h))\n",
    "        h = out * torch.tanh(c)\n",
    "        return h, (h, c)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b7394138-4733-4af4-a395-25c016f9f010",
   "metadata": {},
   "source": [
    "In practice, it's better to do one big matrix multiplication than four smaller ones to improve performance. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 216,
   "id": "8cfb970d-fedd-461c-a565-93eb9a53ceee",
   "metadata": {},
   "outputs": [],
   "source": [
    "class LSTMCell(Module):\n",
    "    def __init__(self, ni, nh):\n",
    "        self.ih = nn.Linear(ni, 4 * nh)\n",
    "        self.hh = nn.Linear(nh, 4 * nh)\n",
    "\n",
    "    def forward(self, input, state):\n",
    "        h, c = state\n",
    "        # One big multiplication for all the gates is better than 4 smaller ones\n",
    "        gates = (self.ih(input) + self.hh(h)).chunk(4, 1) # split into 4 chunks along dim=1\n",
    "        igate, fgate, ogate = map(torch.sigmoid, gates[:3])\n",
    "        cgate = gates[3].tanh()\n",
    "\n",
    "        c = fgate * c + igate * cgate\n",
    "        h = ogate * c.tanh()\n",
    "        return h, (h,c)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e2be15ee-d04b-4017-bbac-4d5012f033e5",
   "metadata": {},
   "source": [
    "Let's illustrate how the model works with dummy data:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 171,
   "id": "36fc111a-58ab-4e29-84aa-9dcb84573632",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([4, 10]) torch.Size([4, 64]) torch.Size([4, 64]) torch.Size([4, 64]) torch.Size([4, 30])\n"
     ]
    }
   ],
   "source": [
    "bs = 4\n",
    "ni = 10  # embedding length\n",
    "nh = 64\n",
    "model = LSTMCell(ni, nh)\n",
    "\n",
    "x = torch.rand((bs, ni))\n",
    "h = torch.rand((bs, nh))\n",
    "c = torch.rand((bs, nh))\n",
    "\n",
    "res, (h1, c1) = model(x, (h, c))\n",
    "pred = nn.Linear(nh, len(vocab))(res)\n",
    "print(x.size(), res.size(), h1.size(), c1.size(), pred.size())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "60da4e23-6133-427a-bfc1-74e13e9bd7fc",
   "metadata": {},
   "source": [
    "Now we can build the full LSTM model:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 221,
   "id": "143e6e17-2b1e-44fa-a7ea-3c7845269f84",
   "metadata": {},
   "outputs": [],
   "source": [
    "class LMModel6(Module):\n",
    "    def __init__(self, vocab_sz, n_embed, n_hidden):\n",
    "        self.i_h = nn.Embedding(vocab_sz, n_embed)\n",
    "        self.cell = LSTMCell(n_embed, n_hidden)\n",
    "        self.h_o = nn.Linear(n_hidden, vocab_sz)\n",
    "        self.state = [torch.zeros(bs, n_hidden) for _ in range(2)]\n",
    "\n",
    "    def forward(self, x):\n",
    "        outs = []\n",
    "        state = self.state\n",
    "        for i in range(sl):\n",
    "            res, state = self.cell(self.i_h(x[:,i]), state)\n",
    "            outs.append(self.h_o(res))\n",
    "        self.state = [h.detach() for h in state]\n",
    "        return torch.stack(outs, dim=1)\n",
    "\n",
    "    def reset(self):\n",
    "        for h in self.state: h.zero_()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 219,
   "id": "a1998196-613b-459d-9023-03d701ac82ff",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Let's regenerate the dataset\n",
    "bs = 4\n",
    "sl = 16  # sequence length\n",
    "seqs = L((tensor(indices[i:i+sl]), tensor(indices[i+1:i+sl+1])) for i in range(0, len(indices)-sl-1, sl))\n",
    "cut = int(len(seqs) * 0.8)\n",
    "dls = DataLoaders.from_dsets(group_chunks(seqs[:cut], bs), group_chunks(seqs[cut:], bs), bs=bs, drop_last=True, shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 212,
   "id": "f3986c4e-58a2-4862-a9ac-729635f62cc0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "30 torch.Size([4, 16]) torch.Size([4, 16]) torch.Size([4, 16, 30])\n",
      "TensorBase(3.4138, grad_fn=<AliasBackward0>)\n"
     ]
    }
   ],
   "source": [
    "# x, y = next(iter(dls.train))\n",
    "out = LMModel6(len(vocab), 64, 64)(x)\n",
    "print(len(vocab), x.size(), y.size(), out.size())\n",
    "print(CrossEntropyLossFlat()(out, y))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 222,
   "id": "2ab96af8-73a9-414f-bbbe-2c7bea67f46d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "<style>\n",
       "    /* Turns off some styling */\n",
       "    progress {\n",
       "        /* gets rid of default border in Firefox and Opera. */\n",
       "        border: none;\n",
       "        /* Needs to be in here for Safari polyfill so background images work as expected. */\n",
       "        background-size: auto;\n",
       "    }\n",
       "    progress:not([value]), progress:not([value])::-webkit-progress-bar {\n",
       "        background: repeating-linear-gradient(45deg, #7e7e7e, #7e7e7e 10px, #5c5c5c 10px, #5c5c5c 20px);\n",
       "    }\n",
       "    .progress-bar-interrupted, .progress-bar-interrupted::-webkit-progress-bar {\n",
       "        background: #F44336;\n",
       "    }\n",
       "</style>\n"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>epoch</th>\n",
       "      <th>train_loss</th>\n",
       "      <th>valid_loss</th>\n",
       "      <th>accuracy</th>\n",
       "      <th>time</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>1.315539</td>\n",
       "      <td>1.654632</td>\n",
       "      <td>0.487389</td>\n",
       "      <td>00:09</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>0.776126</td>\n",
       "      <td>1.284034</td>\n",
       "      <td>0.641339</td>\n",
       "      <td>00:09</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>0.404424</td>\n",
       "      <td>1.415817</td>\n",
       "      <td>0.690831</td>\n",
       "      <td>00:09</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>0.313369</td>\n",
       "      <td>1.339205</td>\n",
       "      <td>0.733423</td>\n",
       "      <td>00:09</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>0.297468</td>\n",
       "      <td>1.569576</td>\n",
       "      <td>0.721050</td>\n",
       "      <td>00:09</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5</td>\n",
       "      <td>0.296873</td>\n",
       "      <td>1.268781</td>\n",
       "      <td>0.726364</td>\n",
       "      <td>00:09</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>6</td>\n",
       "      <td>0.408310</td>\n",
       "      <td>1.720014</td>\n",
       "      <td>0.671716</td>\n",
       "      <td>00:09</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>7</td>\n",
       "      <td>0.308835</td>\n",
       "      <td>1.468801</td>\n",
       "      <td>0.670923</td>\n",
       "      <td>00:09</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>8</td>\n",
       "      <td>0.275845</td>\n",
       "      <td>1.220386</td>\n",
       "      <td>0.755869</td>\n",
       "      <td>00:09</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>9</td>\n",
       "      <td>0.290519</td>\n",
       "      <td>1.007425</td>\n",
       "      <td>0.746193</td>\n",
       "      <td>00:09</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>10</td>\n",
       "      <td>0.208489</td>\n",
       "      <td>1.043861</td>\n",
       "      <td>0.718512</td>\n",
       "      <td>00:09</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>11</td>\n",
       "      <td>0.207362</td>\n",
       "      <td>1.144726</td>\n",
       "      <td>0.734930</td>\n",
       "      <td>00:09</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>12</td>\n",
       "      <td>0.125986</td>\n",
       "      <td>1.223209</td>\n",
       "      <td>0.784105</td>\n",
       "      <td>00:09</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>13</td>\n",
       "      <td>0.092642</td>\n",
       "      <td>1.328272</td>\n",
       "      <td>0.787754</td>\n",
       "      <td>00:09</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>14</td>\n",
       "      <td>0.074361</td>\n",
       "      <td>1.253699</td>\n",
       "      <td>0.783947</td>\n",
       "      <td>00:09</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "learn = Learner(dls, LMModel6(len(vocab), 64, 64), loss_func=CrossEntropyLossFlat(), metrics=accuracy, cbs=ModelResetter)\n",
    "learn.fit_one_cycle(15, 1e-2)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c0a3323c-7e22-4aeb-bafc-2f7b53a479cd",
   "metadata": {},
   "source": [
    "### Regularizing an LSTM\n",
    "\n",
    "Reference: [Regularizing and Optimizing LSTM Language Models](https://arxiv.org/abs/1708.02182)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c04269a1-fe15-424a-b0f4-15fc664f5cba",
   "metadata": {},
   "source": [
    "#### Dropout"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bdf1876d-7b3e-41cc-99be-e3b790e11101",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Dropout(Module):\n",
    "    def __init__(self, p): \n",
    "        self.p = p\n",
    "\n",
    "    def forward(self, x):\n",
    "        if not self.training: return x\n",
    "        mask = x.new(*x.shape).bernoulli_(1-p)\n",
    "        return x * mask.div_(1-p)        "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "560241a0-08e7-4169-81df-3b6bd6b6ba8a",
   "metadata": {},
   "source": [
    "#### Activation Regularization (AR) and Temporal Activation Regularization (TAR)\n",
    "\n",
    "**Activation Regularization (AR)**: let `activations` been all activation weights of the model. Activation Regularization can be achieved by modifying the loss function:\n",
    "\n",
    "```\n",
    "loss += alpha * activations.pow(2).mean()\n",
    "\n",
    "```\n",
    "\n",
    "**Temporal Activation Regularization (TAR)**: since we are dealing with sequential data, the outputs of the LSTM model should somewhat make sense when we read tokens in order. TAR encourages this behavior by adding a penalty to the loss to make the difference between two consecutive activations as small as possible: our activations tensor has a shape `bs x sl x n_hidden`, and we read consecutive activations on the sequence length axis. With this, TAR can be expressed as follows:\n",
    "\n",
    "```\n",
    "loss += beta * (activations[:,1:] - activations[:,:-1]).pow(2).mean()\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f81d892f-400b-4032-b65c-45fc684075df",
   "metadata": {},
   "source": [
    "#### Training a Weight-Tied Regularized LSTM\n",
    "\n",
    "**Weight Tying**: in a language model, the input embeddings represent a mapping from words to activations, and the output hidden layer represetns a mapping from activations to words. We might expect, intuitively, that these mappings could be the same. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 258,
   "id": "9830fa9c-3bd0-47a9-839e-2d0f9e810954",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([30, 5]) torch.Size([30, 5])\n"
     ]
    }
   ],
   "source": [
    "vocab_len = 30\n",
    "n_hidden = 5\n",
    "i_h = nn.Embedding(vocab_len, n_hidden)\n",
    "h_o = nn.Linear(n_hidden, vocab_len)\n",
    "print(i_h.weight.size(), h_o.weight.size())\n",
    "h_o.weight = i_h.weight"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
